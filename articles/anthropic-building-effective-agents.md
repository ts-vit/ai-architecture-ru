# Создание эффективных ИИ-агентов (Building Effective Agents)

*Оригинал статьи: [Anthropic Research](https://www.anthropic.com/research/building-effective-agents)*

За последний год мы работали с десятками команд, создающих агентов на базе больших языковых моделей (LLM) в различных отраслях. Самыми успешными оказались не те реализации, которые использовали сложные фреймворки или специализированные библиотеки. Вместо этого они строились на простых, компонуемых паттернах.

В этом посте мы делимся тем, чему научились в ходе работы с нашими клиентами и при создании собственных агентов, а также даем практические советы разработчикам по созданию эффективных агентов.

---

## Что такое агенты?

Термин «агент» может определяться по-разному. Некоторые клиенты определяют агентов как полностью автономные системы, которые работают независимо в течение длительных периодов времени, используя различные инструменты для решения сложных задач. Другие используют этот термин для описания более жестких реализаций, следующих заранее определенным рабочим процессам. 

В Anthropic мы классифицируем все эти вариации как **агентные системы**, но проводим важное архитектурное различие между **рабочими процессами (workflows)** и **агентами**:

*   **Рабочие процессы (Workflows):** Это системы, в которых LLM и инструменты оркеструются через заранее определенные пути в коде.
*   **Агенты (Agents):** Это системы, в которых LLM динамически управляет своими собственными процессами и использованием инструментов, сохраняя контроль над тем, как выполняются задачи.

Ниже мы подробно рассмотрим оба типа систем. В Приложении 1 («Агенты на практике») мы описываем две области, в которых клиенты нашли особую ценность в использовании таких систем.

---

## Когда (и когда не) использовать агентов

При создании приложений с использованием LLM мы рекомендуем находить максимально простое решение и увеличивать сложность только при необходимости. Это может означать отказ от создания агентных систем вовсе. Агентные системы часто обменивают задержку (latency) и стоимость на более высокую производительность задач, и вам следует подумать, когда такой компромисс оправдан.

Когда оправдана большая сложность, рабочие процессы обеспечивают предсказуемость и последовательность для четко определенных задач, тогда как агенты являются лучшим вариантом, когда в масштабе требуются гибкость и принятие решений на основе моделей. Однако для многих приложений оптимизации одиночных вызовов LLM с помощью поиска (retrieval) и примеров в контексте обычно достаточно.

---

## Когда и как использовать фреймворки

Существует множество фреймворков, которые упрощают реализацию агентных систем, в том числе:
*   Claude Agent SDK;
*   Strands Agents SDK от AWS;
*   Rivet (графический интерфейс для создания рабочих процессов);
*   Vellum (еще один инструмент GUI для тестирования сложных цепочек).

Эти фреймворки облегчают старт, упрощая стандартные низкоуровневые задачи, такие как вызов LLM, определение и парсинг инструментов, а также связывание вызовов в цепочки. Однако они часто создают дополнительные уровни абстракции, которые могут скрывать базовые промпты и ответы, что затрудняет отладку. Они также могут подталкивать к добавлению излишней сложности там, где хватило бы простого решения.

Мы предлагаем разработчикам начинать с прямого использования API LLM: многие паттерны можно реализовать в нескольких строках кода. Если вы все же используете фреймворк, убедитесь, что вы понимаете базовый код. Неверные предположения о том, что происходит «под капотом», являются распространенной причиной ошибок.

---

## Строительные блоки, рабочие процессы и агенты

В этом разделе мы рассмотрим общие паттерны агентных систем, которые мы видели в продакшене. Мы начнем с нашего фундаментального блока — дополненной LLM — и будем постепенно увеличивать сложность.

### Базовый блок: Дополненная LLM (Augmented LLM)
Это LLM, усиленная такими дополнениями, как поиск (retrieval), инструменты (tools) и память (memory). Наши текущие модели могут активно использовать эти возможности — генерировать собственные поисковые запросы, выбирать подходящие инструменты и определять, какую информацию следует сохранить.

Мы рекомендуем сосредоточиться на двух аспектах: адаптации этих возможностей под ваш конкретный случай и обеспечении простого, хорошо задокументированного интерфейса для вашей LLM. Одним из подходов является использование нашего недавно выпущенного **Model Context Protocol (MCP)**.

### Воркфлоу: Цепочки промптов (Prompt Chaining)
Разбивает задачу на последовательность шагов, где каждый вызов LLM обрабатывает вывод предыдущего. Можно добавить программные проверки (gate) на любом промежуточном этапе, чтобы убедиться, что процесс идет по плану.
**Когда использовать:** Идеально, когда задачу можно четко разложить на фиксированные подзадачи. Основная цель — повысить точность за счет упрощения каждого отдельного вызова LLM.

### Воркфлоу: Маршрутизация (Routing)
Классифицирует входные данные и направляет их на специализированную последующую задачу. Это позволяет разделять ответственности и строить более специализированные промпты. Без этого оптимизация под один тип ввода может ухудшить работу с другими типами.
**Когда использовать:** Для сложных задач, где есть четкие категории, которые лучше обрабатывать раздельно.

### Воркфлоу: Параллелизация (Parallelization)
LLM могут работать одновременно над задачей, а их выходные данные затем агрегируются программно. Есть два варианта:
1.  **Секционирование (Sectioning):** Разбиение задачи на независимые подзадачи, выполняемые параллельно.
2.  **Голосование (Voting):** Запуск одной и той же задачи несколько раз для получения различных результатов и выбора лучшего.

### Воркфлоу: Оркестратор-исполнители (Orchestrator-Workers)
Центральная LLM динамически разбивает задачу, делегирует её рабочим LLM и синтезирует их результаты.
**Когда использовать:** Подходит для сложных задач, где вы не можете предсказать необходимые подзадачи заранее (например, в кодинге количество файлов для изменения зависит от самой задачи).

### Воркфлоу: Оценщик-оптимизатор (Evaluator-Optimizer)
Один вызов LLM генерирует ответ, а другой обеспечивает оценку и обратную связь в цикле.
**Когда использовать:** Когда есть четкие критерии оценки и итеративное улучшение приносит измеримую пользу.

---

## Агенты (Agents)

Агенты появляются в продакшене по мере того, как LLM совершенствуются в ключевых навыках: понимании сложного ввода, рассуждении, планировании, надежном использовании инструментов и восстановлении после ошибок. 

Агент начинает работу с команды или обсуждения с пользователем. Как только задача ясна, агент планирует и действует независимо, при необходимости возвращаясь к человеку за уточнениями. В процессе выполнения агенту крайне важно получать «объективную истину» (ground truth) из среды (результаты вызова инструментов или выполнения кода) для оценки своего прогресса.

**Когда использовать:** Для открытых задач, где невозможно предсказать количество шагов и нельзя жестко закодировать путь. Автономия агентов делает их идеальными для масштабирования задач в доверенных средах. Однако это означает более высокие затраты и риск накопления ошибок. Мы рекомендуем тщательное тестирование в песочницах и использование защитных барьеров (guardrails).

---

## Резюме: Три принципа успеха

Успех в сфере LLM — это не создание самой сложной системы, а создание *правильной* системы для ваших нужд.
1.  **Соблюдайте простоту** в дизайне вашего агента.
2.  **Приоритизируйте прозрачность**, явно показывая шаги планирования агента.
3.  **Тщательно проектируйте интерфейс агент-компьютер (ACI)** через детальную документацию инструментов и тестирование.

---

## Приложение 1: Агенты на практике

### А. Поддержка клиентов
Сочетает привычные интерфейсы чат-ботов с расширенными возможностями через инструменты. Идеально подходит, так как:
*   Взаимодействие естественно следует потоку беседы.
*   Инструменты могут подтягивать данные о клиенте и историю заказов.
*   Действия (возврат средств, обновление тикетов) выполняются программно.

### Б. Кодинг-агенты
Пространство разработки ПО показало огромный потенциал: от автодополнения кода до автономного решения проблем. Эффективны, так как:
*   Решения проверяются автоматическими тестами.
*   Агенты могут итерировать на основе результатов тестов.
*   Качество вывода можно измерить объективно.

---

## Приложение 2: Промпт-инжиниринг ваших инструментов

Инструменты — важнейшая часть агента. Описаниям инструментов нужно уделять столько же внимания, сколько и основным промптам.
**Советы по форматам:**
*   Дайте модели достаточно токенов, чтобы «подумать» перед использованием инструмента.
*   Используйте форматы, которые модель часто видела в интернете (JSON, Markdown).
*   Избегайте форматов с большим «оверхедом» (например, необходимость точного подсчета тысяч строк кода).

**Создание хорошего ACI (Agent-Computer Interface):**
1.  **Поставьте себя на место модели:** Очевидно ли, как использовать этот инструмент? Хорошее определение включает примеры, описание крайних случаев и четкие границы.
2.  **Меняйте имена параметров:** Делайте их максимально понятными, как если бы вы писали документацию для младшего разработчика.
3.  **Тестируйте:** Запускайте примеры в Workbench и смотрите, где модель ошибается.
4.  **Poka-yoke (защита от дурака):** Изменяйте аргументы инструментов так, чтобы в них было сложнее совершить ошибку. Например, при создании нашего агента для SWE-bench мы обнаружили, что модель ошибается с относительными путями файлов. Мы изменили инструменты так, чтобы они всегда требовали абсолютные пути — и модель начала работать безупречно.

*Авторы: Erik Schluntz и Barry Zhang (Anthropic).*
